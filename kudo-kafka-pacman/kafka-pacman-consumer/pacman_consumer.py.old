# Before running this program run pip install kafka-python
import datetime
import os, sys
import time
import socket
import logging
import datetime
from kafka import KafkaConsumer, KafkaProducer
from json import loads, dumps


# total messages consumed counter
consumption_counter = 0

print("App started X")

# logging.basicConfig(level=logging.INFO)

def get_producer():
    try:
        producer = KafkaProducer(bootstrap_servers=[os.environ['BROKER_SERVICE']]
                                , value_serializer=lambda x: dumps(x).encode('utf-8')
                                , acks=1
                                , retries=1
                                )
        return producer
    except:
        print("could not connect to Kafka")

def send_message(producer, message):
    msg_json = {message["topic"] : message["value"]}
    producer.send(message["topic"], value=msg_json)
    return [message["topic"], msg_json]




def get_consumer(timeout_ms, group_id, topic, max_poll_records=1000):

    try:
        consumer = KafkaConsumer(
            topic
            , bootstrap_servers=[os.environ['BROKER_SERVICE']]
            , auto_offset_reset='earliest'
            , enable_auto_commit=False
            , consumer_timeout_ms=timeout_ms
            , value_deserializer=lambda x: loads(x.decode('ascii'))
            , group_id=str(group_id)
            , max_poll_records = int(max_poll_records)
            )
        return consumer
    except:
        return "failed to connect to Kafka"


# def count_queue():
#     consumer = get_consumer(1000, 'pacman-jobs-group', os.environ["PACMAN_JOBS_TOPIC"], 1000)
#     consumer.subscribe(os.environ['PACMAN_JOBS_TOPIC'])
#     messages = []
#     for message in consumer:
#         messages.append(dumps(message))
#     print('Message array: ', messages)
#     msg_queue_length = len(messages)
#     print(socket.gethostname(), "-- current message count: ", msg_queue_length, " at ", str(datetime.datetime.now().time()))
    
#     producer = get_producer()
#     send_message(producer, {'topic': "message-queue-count", 'value': msg_queue_length})
#     producer.close()

def execute_job():
    consumer = get_consumer(1000, 'pacman-jobs-group', os.environ['PACMAN_JOBS_TOPIC'])
    consumer.subscribe(os.environ['PACMAN_JOBS_TOPIC'])
    # print(socket.gethostname(), "Got consumer: ", consumer, " at ", str(datetime.datetime.now().time()))
    
    current_job_counter = 0
    for message in consumer:
        current_job_counter += 1            
        global consumption_counter 
        consumption_counter += 1
        if (current_job_counter % 1000 == 0):
            print(socket.gethostname(), '*************** Messages consumed:', consumption_counter)
            print(socket.gethostname(), '------',dumps(message))
            consumer.commit()

    print(socket.gethostname(), " -- Messages consumed total: ", consumption_counter, "-- this job: ", current_job_counter)
    consumer.close()

# on container start, register the pod to the frontend UI
send_message(get_producer(), {"topic": "registered-consumers", "value": socket.gethostname()})

# infinite loop
counter = 0

previous_timestamp = datetime.datetime.now()

messages = []

while True:
    
    execute_job()
    current_timestamp = datetime.datetime.now()
    
    latency = current_timestamp - previous_timestamp
    print("Latency is: ", latency, " for ", socket.gethostname())

    print(socket.gethostname(), "Completed job at ", str(datetime.datetime.now().time()))
    # if counter % 2 == 0:
    #     count_queue()
    # counter += 1
    
    previous_timestamp = current_timestamp
    time.sleep(.01)

